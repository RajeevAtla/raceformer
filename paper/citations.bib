@MISC{coumans2021,
    author =   {Erwin Coumans and Yunfei Bai},
    title =    {PyBullet, a Python module for physics simulation for games, robotics and machine learning},
    howpublished = {\url{http://pybullet.org}},
    year = {2016--2021}
}

@article{ZHANG2025111552,
title = {CMHT autonomous dataset: A multi-sensor dataset including radar and IR for autonomous driving},
journal = {Data in Brief},
volume = {60},
pages = {111552},
year = {2025},
issn = {2352-3409},
doi = {https://doi.org/10.1016/j.dib.2025.111552},
url = {https://www.sciencedirect.com/science/article/pii/S2352340925002847},
author = {Howard Zhang and Ash Liu and Saied Habibi and Martin v. Mohrenschildt and Ryan Ahmed},
keywords = {Autonomous driving, Sensor fusion, LiDAR, Radar, Infrared camera, GPS/IMU},
abstract = {Standardized datasets are essential for the development and evaluation of autonomous driving algorithms. As the types of sensors available to researchers increase, datasets containing a variety of temporally and spatially aligned sensors have become increasingly valuable. This paper presents a driving dataset recorded using a complete sensor suite for research on autonomous driving, perception, and sensor fusion. The dataset consists of over 9000 frames of data recorded at 10-20Hz using a complete sensor suite made up of Velodyne LiDAR, GPS/IMU, mm-wave radar, as well as color and infrared cameras. The capture scenarios include poor weather/lighting conditions, such as rain/night scenarios, and diverse traffic conditions, such as highways and cities with various objects. Both fully synchronized data and raw recordings in the form of ROS2 bags are provided, as well as 3D tracklet labels for individual objects. This paper provides technical details on the driving platform, data format, and utilities.}
}